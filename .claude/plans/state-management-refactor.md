# State Management Consolidation Refactor

_Generated by Claude (REVISE phase) - Revised based on Momus Round 2 critical issues_
_Enhanced by Codex 5.2 (xhigh reasoning) - Added edge cases, security, error handling, performance, testing gaps_

## Context

### Original Request
Refactor state management to consolidate too many state files - merge pipeline-state.json and boulder.json into a unified structure.

### Interview Summary
**Domain**: REFACTOR
**Technical Decisions**:
- Multiple files affected (boulder.py, notepad.py, state_validate.py, schemas)
- Backward compatibility required - must migrate existing state
- Good test coverage (>70%) - safe to refactor
- High risk tolerance - aggressive changes acceptable
- Pain point: Too many state files causing confusion

### CRITICAL ARCHITECTURE REALITY (from Momus Issue 1)

**ACTUAL CODE BEHAVIOR**:
- `boulder.py` IMPORTS `boulder_index.py` (lines 17-19)
- `boulder_index.py` references `.atlas/boulders/` directory (line 21)
- `.atlas/boulders/` directory does NOT exist
- Result: `boulder_index.py` is imported dead code - references non-existent directory

**USER DECISION**: ABANDON boulder_index.py architecture entirely for single unified `.atlas/state.json` file.

### Current State Architecture

**Files**:
1. `.atlas/pipeline-state.json` - Planning pipeline state (phase, codex_choice, plan_mode_active, momus_iterations, plan_name)
2. `.atlas/boulder.json` - Execution state (active, agent, plan, started, progress, wisdom)
3. `scripts/lib/boulder_index.py` - DEAD CODE - imports exist but references non-existent `.atlas/boulders/`

**Problem**:
- Two separate state files causing confusion
- boulder_index.py imports exist in boulder.py but reference architecture never implemented
- 11 hook scripts read pipeline-state.json directly (verified count from audit)
- Duplicated concerns across multiple files

**Solution**: Merge into single `.atlas/state.json` with all fields, REMOVE boulder_index.py imports.

### Metis Review

**Critical Gaps Identified**:
1. `.atlas/boulders/` does NOT exist - per-plan architecture never implemented
2. 11 hook scripts read `pipeline-state.json` directly - MUST update ALL
3. Migration lock needed - prevent hooks reading mid-migration
4. Active Ralph loop conflict - must detect and block migration
5. Schema version detection needed in ALL scripts
6. boulder_index.py is imported dead code - must remove imports and replace functionality

**Guardrails**:
- Do NOT use `.atlas/boulders/` - it doesn't exist
- Do NOT remove pipeline-state.json until ALL hooks updated
- Do NOT migrate without global lock (.atlas/migration.lock)
- Do NOT assume boulder_index.py is ground truth - it's orphaned
- Do NOT update state schema without coordinated hook updates

---

## Codex Enhancement (gpt-5.2-codex xhigh reasoning)

### Edge Cases to Address

1. **Concurrent access during migration**: Define hook behavior when `.atlas/migration.lock` exists (wait/backoff vs fail-fast) to prevent partial reads
2. **Stale lock after crash**: Add TTL/PID metadata to lock file and a safe recovery path so the system doesn't deadlock
3. **Mixed file presence**: Handle when only one of `pipeline-state.json`/`boulder.json` exists, or `state.json` exists alongside old files; define precedence and idempotent migration behavior
4. **Corrupted/truncated state.json**: Require fallback to `.bak` and avoid overwriting with invalid data
5. **Schema version mismatch**: Unknown or missing `schema_version` should trigger explicit error/migration guidance, not silent fallback

### Security Considerations

1. **File permissions**: Enforce restrictive perms on `.atlas/state.json`, `.atlas/migration.lock`, and backups (e.g., 0600/0640) and verify `.atlas/` is not world-writable
2. **Symlink protection**: Protect against symlink/hardlink attacks on state/lock/backup files
3. **Data redaction**: Avoid leaking sensitive data from `wisdom` or plan metadata in logs; redact or log minimal fields only
4. **TOCTOU prevention**: Eliminate lock race by using atomic lock acquisition (`O_CREAT|O_EXCL` or `flock`) rather than check-then-create
5. **Path sanitization**: Sanitize `plan_name`/`plan_file` if used in path construction to prevent traversal

### Error Handling Requirements

1. **Lock failures**: Clear exit codes and guidance; optional bounded retry/backoff for hooks
2. **JSON parse errors**: Route to recovery (`state-restore` or `.bak`), never auto-overwrite
3. **Missing fields**: Explicit defaults vs hard-fail policy during migration; surface which fields were missing
4. **Disk full/fsync errors**: Preserve old files, clean temp files, and report `ENOSPC` clearly
5. **Permission denied**: Fail early with actionable messages; avoid partial state creation

### Performance Optimizations

1. **Reduce jq calls**: Read state once per script via `hook-common.sh` and reuse values
2. **Lock contention**: Prefer shared read locks or a read-only fast path plus migration lock check
3. **State file growth**: Add pruning/archiving or size caps for `wisdom`/`progress` to prevent slow reads
4. **Validation timing**: Validate jsonschema on write and/or sample reads, not every read
5. **Migration idempotency**: Ensure migration is not accidentally triggered repeatedly by hooks

### Additional Testing Required

1. **Concurrent stress tests**: Many hooks + `boulder.py` writes while migration lock toggles
2. **Chaos tests**: Kill migration between backup creation and rename; assert recovery
3. **Corruption recovery tests**: Truncated `state.json` with fallback to backups
4. **Mixed presence tests**: Only old files, only new file, both present, unknown `schema_version`
5. **Permission/ENOSPC tests**: Simulate errors during backup/write/rename

---

## Work Objectives

### Core Objective
Consolidate `.atlas/pipeline-state.json` and `.atlas/boulder.json` into single `.atlas/state.json`, eliminating state fragmentation while coordinating updates to 11 hook scripts and removing boulder_index.py dependency.

### Concrete Deliverables
1. Updated schema: `scripts/lib/state_schema.json` with merged state (execution + pipeline)
2. Migration script: `scripts/migrate-state-to-unified.py` with global lock
3. Updated `boulder.py` CLI - uses `.atlas/state.json`, removes boulder_index imports
4. Updated `notepad.py` - uses `.atlas/state.json`, removes boulder_index imports
5. Updated validation: `state_validate.py` - validates unified schema
6. Updated 11 hook scripts - read `.atlas/state.json` instead of `pipeline-state.json`
7. Integration tests for hook + state interactions
8. Test updates for new schema
9. Deprecation notices and migration guide

### Definition of Done
- [ ] All state operations use `.atlas/state.json` only - `./scripts/boulder.py status --json`
- [ ] Pipeline fields (phase, momus_iterations) in unified state - verify with `cat .atlas/state.json`
- [ ] Migration script with lock mechanism - `./scripts/migrate-state-to-unified.py --dry-run`
- [ ] All 11 hook scripts updated - `rg 'pipeline-state\.json' scripts/` returns 0 active references (excluding migration/docs)
- [ ] All tests pass - `pytest tests/ -v`
- [ ] Integration tests for hooks pass - `pytest tests/integration/test_hook_state.py -v`

### Must Have
- Single unified `.atlas/state.json` with execution + pipeline fields
- Migration lock to prevent race conditions
- All 11 hook scripts updated in coordinated manner
- Active Ralph loop detection (block migration if running)
- Schema version detection in all scripts
- Backward compatibility via migration script
- All existing tests updated and passing
- boulder_index.py imports removed, functionality replaced

### Must NOT Have (Guardrails)
- Do NOT use `.atlas/boulders/` directory (doesn't exist)
- Do NOT update state schema without updating ALL hook scripts
- Do NOT migrate without global lock (.atlas/migration.lock)
- Do NOT remove pipeline-state.json until ALL hooks verified updated
- Do NOT treat boulder_index.py as ground truth (it's orphaned code)
- Do NOT skip hook integration tests

---

## Prerequisites

### Dependencies
- Python 3.8+
- jsonschema library (already in project)
- pytest, pytest-cov (test dependencies)

### Required Knowledge
- JSON schema design
- Atomic file operations with locking
- Hook script patterns in this codebase
- State validation patterns (see state_validate.py)

### Environment Setup
```bash
# Verify test environment
pytest --version
python -c "import jsonschema; print(jsonschema.__version__)"

# Backup current state
cp .atlas/pipeline-state.json .atlas/pipeline-state.json.bak
cp .atlas/boulder.json .atlas/boulder.json.bak

# Verify no active Ralph loop (migration blocker)
if grep -q 'active.*true' .atlas/ralph-loop.local.md 2>/dev/null; then echo "ERROR: Ralph loop running"; else echo "OK"; fi
```

---

## Verification Strategy

### Test Decision
- **Infrastructure exists**: YES (pytest + good coverage)
- **User wants tests**: TDD
- **Framework**: pytest
- **Coverage Goals**: Maintain >70% coverage (scripts/*.py and scripts/lib/*.py)

### TDD Approach

Each task follows RED-GREEN-REFACTOR:
1. **RED**: Write failing test for unified schema behavior
2. **GREEN**: Implement minimum code to pass
3. **REFACTOR**: Clean up while keeping tests green

---

## Task Flow

```
Task 0 (Verify) → Task 1 (Schema) → Task 2 (Validation) → Task 3 (Migration with Lock)
                                                                      ↓
                                      Task 4 (boulder.py) → Task 5 (notepad.py)
                                                                      ↓
                                      Task 6 (Tests) → Task 8 (11 Hook Scripts) → Task 9 (Hook Tests + Rollback Test)
                                                                      ↓
                                                      Task 7 (Cleanup + Docs)
```

## Parallelization

| Group | Tasks | Reason |
|-------|-------|--------|
| A | 4, 5 | Both consume new schema, can update independently |
| B | 8 (hook updates) | Can parallelize after schema stable |

---

## TODOs

### Task 0. Verify Architecture and Audit Hook Dependencies (REVISED)

**What to do**:
- Verify `.atlas/boulders/` does NOT exist (confirm Metis finding)
- Audit ALL scripts that read `pipeline-state.json` or `boulder.json` with exact command
- Run: `rg 'pipeline-state\.json' scripts/ -l` to get complete list (NOT hooks/, files are in scripts/)
- Create comprehensive list of affected files in audit report
- Document current state file usage patterns
- Identify Ralph loop detection mechanism - parse YAML frontmatter from .atlas/ralph-loop.local.md, check active: true
- Mark boulder_index.py as dead code in comments

**Must NOT do**:
- Don't assume any architecture exists without verification
- Don't skip any script in the audit
- Don't modify files yet (audit only)

**Complexity**: 2/10
**Location**: `.atlas/`, `scripts/` (audit across codebase)
**Dependencies**: None
**Parallelizable**: NO (foundation for all other tasks)

**Manual Verification**:
- Step 1: Check if `.atlas/boulders/` exists - `ls .atlas/boulders/ 2>&1`
- Step 2: Find all pipeline-state.json references - `rg 'pipeline-state\.json' scripts/ -l`
- Step 3: Find all boulder.json references - `rg 'boulder\.json' scripts/ -l`
- Step 4: Check Ralph loop state file - `cat .atlas/ralph-loop.local.md`
- Expected: Boulders directory missing, 11 files reference pipeline-state.json

**References**:

**Pattern References**:
- `scripts/lib/hook-common.sh` - Hook state reading patterns (NOT hooks/lib/)
- `scripts/lib/pipeline-state-machine.sh` - Pipeline state machine patterns (NOT hooks/pipeline-transition.sh)

**Acceptance Criteria**:
- [ ] Verified `.atlas/boulders/` does NOT exist - command: `test ! -d .atlas/boulders/ && echo PASS`
- [ ] Complete list of hook scripts reading pipeline-state.json - documented in audit report (exact count: 11)
- [ ] Complete list of Python scripts reading boulder.json - documented in audit report
- [ ] Ralph loop detection mechanism identified - parse YAML frontmatter from .atlas/ralph-loop.local.md, check if active: true
- [ ] boulder_index.py marked as dead code - add comment at top of file
- [ ] Audit report saved - `.atlas/AUDIT-state-files.md`

**Commit**: YES
- Message: `audit(state): verify architecture and document all state file dependencies`
- Files: `.atlas/AUDIT-state-files.md`, `scripts/lib/boulder_index.py` (add dead code comment)

**Rollback Strategy**:
```bash
git revert <commit-hash>
```

---

### Task 1. Define Unified State Schema (REVISED)

**What to do**:
- Create unified schema in `scripts/lib/state_schema.json` merging ALL fields from both files
- Pipeline fields: phase, codex_choice, plan_mode_active, momus_iterations, plan_name, plan_file
- Execution fields: active_plan, started, progress (object), wisdom (object)
- Add migration_version field (integer, default 1) - increments when data migration happens
- Add schema_version field (string, e.g. "unified-v1") - changes when schema structure changes
- Document all fields with descriptions
- NO per-plan structure - single flat unified object

**Must NOT do**:
- Don't reference `.atlas/boulders/` (doesn't exist)
- Don't break existing required fields during merge
- Don't add fields not used by current system

**Complexity**: 4/10
**Location**: `scripts/lib/state_schema.json:1-150`
**Dependencies**: Task 0 (audit complete)
**Parallelizable**: NO (all other tasks depend on this)

**Test-First Approach**:
- **RED**: Write test in `tests/unit/test_unified_schema.py` (CREATE new file) that validates merged schema structure
- **GREEN**: Define unified schema in state_schema.json
- **REFACTOR**: Clean up redundant definitions, add field descriptions
- Additional tests: Validate all required fields, validate enum values for phase

**References**:

**Pattern References**:
- `scripts/lib/state_schema.json` - Existing pipeline_state and boulder schemas to merge

**API/Type References**:
- Pipeline fields: phase (enum: INTERVIEW|GENERATE|REVISE|ENHANCE|COMPLETE), plan_name, plan_file, codex_choice, plan_mode_active (bool), momus_iterations (int)
- Execution fields: active_plan, started (ISO timestamp), progress (object with tasks array), wisdom (object with categories)

**Acceptance Criteria**:
- [ ] Schema has all pipeline fields - validate with jsonschema
- [ ] Schema has all execution fields - validate structure
- [ ] Schema includes migration_version (data migration counter) and schema_version (structure version) fields - check schema definition
- [ ] migration_version vs schema_version semantics documented in schema description field
- [ ] Schema is FLAT (no nested per-plan structure) - verify structure
- [ ] Schema validates sample unified state - `python -c "import jsonschema, json; jsonschema.validate(instance, schema)"`
- [ ] Test file CREATED: `tests/unit/test_unified_schema.py` (new file)
- [ ] `pytest tests/unit/test_unified_schema.py -v` → PASS

**Commit**: YES
- Message: `refactor(state): define unified state schema merging pipeline + execution (single file)`
- Files: `scripts/lib/state_schema.json`, `tests/unit/test_unified_schema.py`

**Rollback Strategy**:
```bash
git revert <commit-hash>
```

---

### Task 2. Update State Validation for Unified Schema (REVISED)

**What to do**:
- Update `state_validate.py` to validate unified state schema
- Add validate_unified_state() function (NOT validate_unified_boulder - wrong name)
- Update existing validation functions to handle transition period
- Add schema version detection (check schema_version field)
- Keep backward compatibility for old formats during migration
- Remove any references to boulder_index.py patterns

**Must NOT do**:
- Don't remove old validation functions yet (needed for migration)
- Don't break existing validation API
- Don't reference `.atlas/boulders/` directory

**Complexity**: 5/10
**Location**: `scripts/lib/state_validate.py:1-250`
**Dependencies**: Task 1 (unified schema defined)
**Parallelizable**: NO (depends on Task 1)

**Test-First Approach**:
- **RED**: Write test that validates unified state with all fields (pipeline + execution)
- **GREEN**: Implement validate_unified_state() function
- **REFACTOR**: Extract common validation patterns, simplify version detection
- Additional tests: Test schema_version detection, test backward compatibility with old formats

**References**:

**Pattern References**:
- `scripts/lib/state_validate.py:45-89` - Existing validation patterns

**API/Type References**:
- `scripts/lib/state_schema.json` - Unified schema from Task 1

**Test References**:
- `tests/unit/test_state_validate.py` - Existing validation test patterns

**Acceptance Criteria**:
- [ ] validate_unified_state() function exists - check function signature
- [ ] Validates all pipeline fields (phase enum, momus_iterations int, plan_mode_active bool) - test with valid sample
- [ ] Validates all execution fields (active_plan, progress object, wisdom object) - test structure
- [ ] Detects schema_version field - test version detection
- [ ] Backward compatibility for old formats - test with old pipeline-state.json format
- [ ] No references to boulder_index.py - verify with grep
- [ ] `pytest tests/unit/test_state_validate.py -v` → PASS

**Commit**: YES
- Message: `refactor(state): add unified state validation with schema version detection`
- Files: `scripts/lib/state_validate.py`, `tests/unit/test_state_validate.py`

**Rollback Strategy**:
```bash
git revert <commit-hash>
```

---

### Task 3. Create State Migration Script with Global Lock (REVISED)

**What to do**:
- Create `scripts/migrate-state-to-unified.py`
- Acquire global lock (.atlas/migration.lock) before ANY operations
- Detect active Ralph loop - Parse YAML frontmatter from .atlas/ralph-loop.local.md, check if active: true. If true, exit with error. If file missing or active: false, proceed.
- Read `.atlas/pipeline-state.json` (all fields)
- Read `.atlas/boulder.json` (all fields)
- Merge into single `.atlas/state.json` with unified schema
- Add schema_version="unified-v1" and migration_version=1
- Add --dry-run flag for testing
- Add --backup flag (mandatory, creates .bak files)
- Release lock on completion or error
- Comprehensive logging of all actions

**Must NOT do**:
- Don't proceed without acquiring lock first
- Don't migrate if Ralph loop is active
- Don't delete old files (just mark deprecated)
- Don't migrate if validation fails
- Don't overwrite existing .atlas/state.json without --force flag

**Complexity**: 7/10
**Location**: `scripts/migrate-state-to-unified.py` (new file ~200 lines)
**Dependencies**: Task 1 (schema), Task 2 (validation)
**Parallelizable**: NO (depends on Tasks 1, 2)

**Test-First Approach**:
- **RED**: Write test in `tests/unit/test_migrate_unified.py` (CREATE new file) for migration with sample pipeline + boulder state
- **GREEN**: Implement migration script with lock, Ralph detection, merge logic
- **REFACTOR**: Extract validation, lock management, Ralph detection into helpers
- Additional tests: Dry-run mode, lock acquisition failure, Ralph loop active, missing files, validation errors

**References**:

**Pattern References**:
- `scripts/lib/boulder_index.py:61-94` - Lock patterns (CORRECT: lines 61-94 for lock, NOT 156-198)
- `scripts/lib/boulder_index.py:156-198` - Atomic write patterns (for file operations)
- `scripts/migrate-boulder-state.py:1-100` - Existing migration script structure
- `.atlas/ralph-loop.local.md` - Ralph loop state format (parse YAML frontmatter)

**API/Type References**:
- `scripts/lib/state_schema.json` - Unified schema for output validation
- `scripts/lib/state_validate.py:validate_unified_state()` - From Task 2

**Test References**:
- `tests/unit/test_state_restore.py` - File operation test patterns

**Acceptance Criteria**:
- [ ] Acquires .atlas/migration.lock before operations - test lock file created
- [ ] Detects active Ralph loop and blocks - Parse YAML frontmatter from .atlas/ralph-loop.local.md, check active: true, exit if true
- [ ] Merges pipeline-state.json + boulder.json fields - test with sample files
- [ ] Adds schema_version and migration_version - verify in output
- [ ] --dry-run shows changes without writing - verify no files modified
- [ ] --backup creates .bak files (mandatory) - check .bak files exist
- [ ] Releases lock on completion or error - verify lock file removed
- [ ] Validates output against unified schema - test validation call
- [ ] Logs all migration actions - check stdout/log file
- [ ] Test file CREATED: `tests/unit/test_migrate_unified.py` (new file)
- [ ] `pytest tests/unit/test_migrate_unified.py -v` → PASS

**Commit**: YES
- Message: `feat(state): add migration script with global lock and Ralph loop detection`
- Files: `scripts/migrate-state-to-unified.py`, `tests/unit/test_migrate_unified.py`

**Rollback Strategy**:
```bash
git revert <commit-hash>
# If lock file stuck: rm .atlas/migration.lock
```

---

### Task 4. Update boulder.py for Unified State (REVISED)

**What to do**:
- Update boulder.py to read/write `.atlas/state.json` (NOT .atlas/boulders/)
- Remove all boulder_index.py imports (lines 17-19)
- Replace boulder_index functions:
  - read_index() → direct JSON load from .atlas/state.json
  - write_index() → atomic write with temp file + rename
  - boulder_lock() → fcntl.flock() on state file
- Implement simple file-based locking (fcntl or equivalent)
- Update start, stop, task, wisdom, status, switch, archive commands (correct CLI command names)
- Add pipeline state management functions (get_phase, set_phase, increment_momus)
- Update status to include all pipeline fields (NOT get_status - command is 'status')
- Preserve atomic write operations
- Add schema_version check on read

**Must NOT do**:
- Don't use boulder_index.py (orphaned code)
- Don't reference `.atlas/boulders/` directory
- Don't remove CLI commands (maintain API compatibility)
- Don't skip validation when writing state
- Don't break during migration period (handle both old and new formats)

**Complexity**: 6/10
**Location**: `scripts/boulder.py:1-400`
**Dependencies**: Task 1 (schema), Task 2 (validation), Task 3 (migration exists)
**Parallelizable**: YES (with Task 5) - independent file operations

**Test-First Approach**:
- **RED**: Write test in `tests/unit/test_boulder.py` (CREATE new file) for get_phase(), set_phase() with unified state
- **GREEN**: Implement pipeline state management, remove boulder_index usage
- **REFACTOR**: Extract common state read/write patterns, simplify locking
- Additional tests: Test all CLI commands with unified schema, test lock acquisition

**References**:

**Pattern References**:
- `scripts/boulder.py:120-180` - Existing CLI command structure
- `scripts/migrate-state-to-unified.py` - Lock patterns from Task 3

**API/Type References**:
- `scripts/lib/state_schema.json` - Unified schema from Task 1
- `scripts/lib/state_validate.py:validate_unified_state()` - From Task 2

**Test References**:
- `tests/unit/test_state_validate.py` - State operation test patterns

**Acceptance Criteria**:
- [ ] No boulder_index.py imports - verify with grep
- [ ] start command initializes .atlas/state.json - test with `boulder.py start --plan test`
- [ ] status command includes pipeline fields - `boulder.py status --json` shows phase, momus_iterations (NOT get_status)
- [ ] set_phase updates phase field - test phase transition
- [ ] All operations validate with validate_unified_state() - verify validation calls
- [ ] File locking implemented - test concurrent access
- [ ] Schema version check on read - test with old format triggers error/migration prompt
- [ ] Test file CREATED: `tests/unit/test_boulder.py` (new file)
- [ ] `pytest tests/unit/test_boulder.py -v` → PASS

**Commit**: YES
- Message: `refactor(boulder): migrate to unified state.json, remove boulder_index dependency`
- Files: `scripts/boulder.py`, `tests/unit/test_boulder.py`

**Rollback Strategy**:
```bash
git revert <commit-hash>
```

---

### Task 5. Update notepad.py to Use Unified State (REVISED)

**What to do**:
- Remove references to flat `.atlas/boulder.json`
- Remove boulder_index.py imports
- Read active_plan from `.atlas/state.json` directly
- Update wisdom operations to write to unified state
- Verify all notepad operations work with unified schema
- Add schema_version check

**Must NOT do**:
- Don't use boulder_index.py (orphaned)
- Don't change notepad file structure (`.atlas/notepads/{plan}/` still used for markdown)
- Don't break wisdom accumulation patterns
- Don't skip plan existence validation

**Complexity**: 4/10
**Location**: `scripts/notepad.py:1-120`
**Dependencies**: Task 1 (schema), Task 2 (validation), Task 3 (migration exists)
**Parallelizable**: YES (with Task 4) - different file, independent operations

**Test-First Approach**:
- **RED**: Write test in `tests/unit/test_notepad.py` (CREATE new file) for notepad operations reading from unified state
- **GREEN**: Replace boulder_index calls with direct state.json reads
- **REFACTOR**: Simplify plan detection logic, remove dead imports
- Additional tests: Test wisdom write to unified state, test plan not found error

**References**:

**Pattern References**:
- `scripts/notepad.py:20-40` - Existing wisdom write patterns
- `scripts/boulder.py` - State reading patterns from Task 4

**API/Type References**:
- `.atlas/state.json` - Read active_plan field directly
- `scripts/lib/state_validate.py:validate_unified_state()` - Validate before read

**Test References**:
- `tests/unit/test_state_validate.py` - State operation test patterns

**Acceptance Criteria**:
- [ ] No boulder_index.py imports - verify with grep
- [ ] No references to flat boulder.json - `grep -n 'boulder\.json' scripts/notepad.py` returns 0 (except comments)
- [ ] Reads active_plan from .atlas/state.json - verify import and reads
- [ ] Wisdom operations work with unified schema - test `notepad.py add --category decision --entry "test"`
- [ ] Schema version check on read - test with old format
- [ ] Test file CREATED: `tests/unit/test_notepad.py` (new file)
- [ ] `pytest tests/unit/test_notepad.py -v` → PASS

**Commit**: YES
- Message: `refactor(notepad): use unified state.json, remove boulder_index dependency`
- Files: `scripts/notepad.py`, `tests/unit/test_notepad.py`

**Rollback Strategy**:
```bash
git revert <commit-hash>
```

---

### Task 6. Update Tests for Unified Schema

**What to do**:
- Update all existing state tests to use unified schema
- Update test fixtures to generate unified state (not split files)
- Add new test cases for pipeline state management in unified structure
- Update integration tests if needed
- Add migration script tests
- Verify all edge cases covered (lock failures, Ralph active, etc.)

**Must NOT do**:
- Don't skip migration test coverage
- Don't reduce overall test coverage
- Don't remove backward compatibility tests (needed during transition)

**Complexity**: 5/10
**Location**: `tests/unit/test_state_validate.py`, `tests/unit/test_state_restore.py`, `tests/unit/test_state_recover.py`, `tests/conftest.py`
**Dependencies**: Tasks 1-5 (all implementations complete)
**Parallelizable**: NO (needs all prior tasks complete)

**Test-First Approach**:
- **RED**: Identify failing tests with new schema
- **GREEN**: Update fixtures and test data to use unified state
- **REFACTOR**: Extract common test data generators for unified state
- Additional tests: End-to-end workflow tests, lock contention tests, Ralph detection tests

**References**:

**Pattern References**:
- `tests/conftest.py:1-50` - Fixture patterns
- `tests/unit/test_state_validate.py:1-100` - Existing test structure

**API/Type References**:
- All updated scripts from Tasks 1-5

**Acceptance Criteria**:
- [ ] All state validation tests updated - `pytest tests/unit/test_state_validate.py -v` → PASS
- [ ] Integration tests pass - `pytest tests/integration/ -v` → PASS (if any exist)
- [ ] Coverage maintained >70% for scripts/*.py and scripts/lib/*.py - `pytest tests/ --cov=scripts --cov-report=term-missing`
- [ ] New pipeline state tests added - verify test_get_phase, test_set_phase exist
- [ ] Migration script tests comprehensive - verify lock, Ralph detection, merge logic tests
- [ ] All tests pass - `pytest tests/ -v`

**Commit**: YES
- Message: `test(state): update all tests for unified state schema`
- Files: `tests/unit/test_state_validate.py`, `tests/unit/test_state_restore.py`, `tests/unit/test_state_recover.py`, `tests/conftest.py`

**Rollback Strategy**:
```bash
git revert <commit-hash>
```

---

### Task 8. Update 11 Hook Scripts for Unified State (REVISED from Momus Round 2)

**What to do**:
- Update ALL hooks that read `pipeline-state.json` to read `.atlas/state.json`
- From Task 0 audit with exact command `rg 'pipeline-state\.json' scripts/ -l`, update these 11 scripts:
  - scripts/plan-ready-handler.sh
  - scripts/momus-loop-handler.sh
  - scripts/lib/pipeline-state-machine.sh (NOT hooks/pipeline-transition.sh)
  - scripts/AGENTS.md (documentation file - update text at lines 64, 66, 142)
  - scripts/lib/hook-common.sh
  - scripts/state-recover.sh
  - scripts/state-restore.sh
  - scripts/diagnose-state.sh
  - scripts/codex-completion-handler.sh
  - scripts/migrate-boulder-state.py
  - scripts/lib/state_validate.py
- Add schema_version check in hook-common.sh (shared utility)
- Use jq to read from unified structure (for shell scripts)
- Add fallback for old format during transition period
- Test each hook individually after update
- **NOTE**: scripts/AGENTS.md is a documentation file - update involves changing text references from pipeline-state.json to state.json, NOT implementing state reading logic

**Must NOT do**:
- Don't update only some hooks (all or nothing for consistency)
- Don't skip schema version checks
- Don't break during transition period (must handle both formats temporarily)
- Don't remove old file reads without verification all hooks updated

**Complexity**: 7/10
**Location**: 11 files in `scripts/` and `scripts/lib/` (from audit - ALL paths are scripts/, NOT hooks/)
**Dependencies**: Tasks 1-6 (schema and Python scripts complete)
**Parallelizable**: YES (each hook can be updated independently after schema stable)

**Test-First Approach**:
- **RED**: Write integration test that calls each hook with unified state
- **GREEN**: Update hooks one by one, verify each with test
- **REFACTOR**: Extract common state reading patterns to hook-common.sh
- Additional tests: Test fallback to old format, test schema version detection

**References**:

**Pattern References**:
- `scripts/lib/hook-common.sh` - Shared utilities for state access (NOT hooks/lib/)
- `scripts/lib/pipeline-state-machine.sh` - Pipeline state machine patterns (NOT hooks/pipeline-transition.sh)

**API/Type References**:
- `.atlas/state.json` - All hooks now read from this single file
- Schema fields: phase, plan_mode_active, momus_iterations, plan_name, plan_file

**Test References**:
- Create new: `tests/integration/test_hook_state.py` - Hook integration tests

**Acceptance Criteria**:
- [ ] All 11 hooks updated (verified against Task 0 audit list with exact command) - check each file
- [ ] scripts/AGENTS.md updated - text references changed from pipeline-state.json to state.json at lines 64, 66, 142
- [ ] hook-common.sh has schema_version check function - verify function exists
- [ ] All hooks use jq to read from .atlas/state.json - grep for state.json in scripts/
- [ ] Fallback to old format during transition - test with old pipeline-state.json
- [ ] Each hook tested individually - manual smoke test each hook
- [ ] No active references to pipeline-state.json in scripts/ - `rg 'pipeline-state\.json' scripts/ -l` returns only migration/docs files
- [ ] Test file created: `tests/integration/test_hook_state.py`

**Commit**: YES
- Message: `refactor(hooks): update all 11 hooks to use unified state.json`
- Files: All 11 hook files from audit (including scripts/AGENTS.md), `tests/integration/test_hook_state.py`

**Rollback Strategy**:
```bash
git revert <commit-hash>
# Or manual: Restore hooks from backup
git checkout HEAD~1 -- scripts/
```

---

### Task 9. Integration Tests for Hook + State Interactions (REVISED - Add Rollback Test)

**What to do**:
- Create comprehensive integration tests for hook + state interactions
- Test plan-ready-handler.sh with unified state
- Test momus-loop-handler.sh with unified state
- Test pipeline-state-machine.sh state machine with unified state (NOT pipeline-transition.sh)
- Test keyword-detector.sh state reads
- Test state-recover.sh and state-restore.sh with new format
- Verify all hooks handle schema_version correctly
- Test coordinated state updates (e.g., plan creation → hook reads)
- **ADD ROLLBACK TEST**: Test that reverting commits restores old state files correctly

**Must NOT do**:
- Don't skip any critical hook in test coverage
- Don't test hooks in isolation only (need end-to-end tests)
- Don't mock state files (use real .atlas/state.json)

**Complexity**: 6/10
**Location**: `tests/integration/test_hook_state.py`, `tests/integration/test_pipeline_hooks.py` (new files)
**Dependencies**: Task 8 (all hooks updated)
**Parallelizable**: NO (depends on Task 8 completion)

**Test-First Approach**:
- **RED**: Write integration test for each critical hook workflow
- **GREEN**: Verify hooks work with real unified state
- **REFACTOR**: Extract common test setup (state fixtures, hook invocation helpers)
- Additional tests: Test hook failures, test migration period (old + new formats), test lock contention, **test rollback procedure**

**References**:

**Pattern References**:
- `tests/integration/test_agent_output.py` - Integration test patterns (if exists)
- `scripts/lib/hook-common.sh` - Hook utilities to test

**API/Type References**:
- `.atlas/state.json` - Real state file used in tests
- All hook scripts from Task 8

**Acceptance Criteria**:
- [ ] plan-ready-handler integration test - verify state update after plan ready
- [ ] momus-loop-handler integration test - verify momus_iterations increment
- [ ] pipeline-state-machine integration test - verify phase transitions (NOT pipeline-transition.sh)
- [ ] keyword-detector integration test - verify state reads for routing
- [ ] state-recover integration test - verify recovery with new format
- [ ] Rollback test - verify reverting commits restores old state files and hooks work
- [ ] All integration tests pass - `pytest tests/integration/test_hook_state.py -v` → PASS
- [ ] Coverage for all critical hooks - verify test exists for each from audit

**Commit**: YES
- Message: `test(hooks): add integration tests for hook + unified state interactions including rollback`
- Files: `tests/integration/test_hook_state.py`, `tests/integration/test_pipeline_hooks.py`

**Rollback Strategy**:
```bash
git revert <commit-hash>
```

---

### Task 7. Deprecation Notices, Cleanup, and Migration Guide (REVISED)

**What to do**:
- Create `.atlas/MIGRATION.md` with step-by-step migration instructions
- Document rollback procedure in MIGRATION.md (tested in Task 9)
- Update CLAUDE.md to reflect unified state structure (.atlas/state.json)
- Add deprecation warnings in scripts that detect old formats
- Mark boulder_index.py with clear "DEAD CODE" comment at top
- Document coordinated rollback for state + hooks (critical)
- Add migration checklist (backup, Ralph check, dry-run, verify hooks, migrate)

**Must NOT do**:
- Don't delete old state files (users must migrate manually)
- Don't delete boulder_index.py yet (mark as dead code only)
- Don't remove migration scripts (needed for future users)
- Don't break existing workflows during transition

**Complexity**: 4/10
**Location**: `CLAUDE.md`, `.atlas/MIGRATION.md` (new), `scripts/lib/boulder_index.py` (add comment), various scripts for deprecation warnings
**Dependencies**: Tasks 1-6, 8-9 (all features complete)
**Parallelizable**: NO (final documentation task)

**Manual Verification**:
- Step 1: Read MIGRATION.md - verify clear step-by-step instructions
- Step 2: Check deprecation warnings appear when old formats detected
- Step 3: Verify CLAUDE.md accurately reflects new structure
- Step 4: Verify rollback procedure documented for coordinated state + hook rollback (tested in Task 9)
- Expected: Clear migration path, tested coordinated rollback strategy

**References**:

**Pattern References**:
- `CLAUDE.md:50-100` - Existing documentation structure
- `scripts/migrate-boulder-state.py:1-30` - Existing migration doc patterns

**Acceptance Criteria**:
- [ ] MIGRATION.md created with migration steps - verify file exists and is comprehensive
- [ ] MIGRATION.md has coordinated rollback section (state + hooks) tested in Task 9 - verify instructions
- [ ] CLAUDE.md updated with unified state structure - check "State Directory" section
- [ ] boulder_index.py marked as "DEAD CODE - DO NOT USE" - verify comment at top
- [ ] Deprecation warnings added to scripts detecting old formats - test with old state files
- [ ] Migration checklist documented (backup, Ralph check, dry-run, verify, migrate) - verify in MIGRATION.md

**Commit**: YES
- Message: `docs(state): add migration guide, mark boulder_index as dead code, update CLAUDE.md`
- Files: `CLAUDE.md`, `.atlas/MIGRATION.md`, `scripts/lib/boulder_index.py` (comment only), deprecation warnings in various scripts

**Rollback Strategy**:
```bash
git revert <commit-hash>
# Or manual: Restore CLAUDE.md from git
git checkout HEAD~1 -- CLAUDE.md
```

---

## Commit Strategy

| After Task | Message | Files | Verification |
|------------|---------|-------|--------------|
| 0 | `audit(state): document all state file dependencies` | AUDIT-state-files.md, boulder_index.py | Manual review |
| 1 | `refactor(state): define unified state schema` | state_schema.json, tests | pytest tests/unit/test_unified_schema.py |
| 2 | `refactor(state): add unified state validation` | state_validate.py, tests | pytest tests/unit/test_state_validate.py |
| 3 | `feat(state): add migration script with lock` | migrate-state-to-unified.py, tests | pytest tests/unit/test_migrate_unified.py |
| 4 | `refactor(boulder): migrate to unified state.json` | boulder.py, tests | pytest tests/unit/test_boulder.py |
| 5 | `refactor(notepad): use unified state.json` | notepad.py, tests | pytest tests/unit/test_notepad.py |
| 6 | `test(state): update all tests for unified schema` | all test files | pytest tests/ -v |
| 8 | `refactor(hooks): update all hooks to unified state` | 11 hook files, tests | pytest tests/integration/test_hook_state.py |
| 9 | `test(hooks): add hook integration tests` | integration tests | pytest tests/integration/ -v |
| 7 | `docs(state): migration guide and deprecation` | CLAUDE.md, MIGRATION.md | Manual review |

---

## Risks & Mitigation

| Risk | Severity | Probability | Mitigation |
|------|----------|-------------|------------|
| Breaking active execution state | HIGH | MEDIUM | Comprehensive tests, migration script with --dry-run, mandatory backups, global lock |
| Hook scripts break after state changes | HIGH | HIGH | Coordinated update of all 11 hooks, integration tests, fallback to old format during transition |
| Data loss during migration | HIGH | LOW | Mandatory --backup flag, validation before writing, atomic operations, global lock |
| Schema version conflicts | MEDIUM | LOW | Add schema_version field, detect in all scripts, clear migration path |
| Ralph loop conflict during migration | HIGH | LOW | Detect active Ralph in migration script, block migration if running, document in MIGRATION.md |
| Hooks reading mid-migration | HIGH | MEDIUM | Global lock (.atlas/migration.lock), all hooks check for lock before reading |
| Forgetting to update a hook | MEDIUM | MEDIUM | Task 0 audit creates comprehensive list with exact command, Task 8 verification checklist |

---

## Rollback Plan

### Per-Task Rollback

Each task commit can be reverted independently (see individual Rollback Strategy sections above).

### Coordinated Rollback (Critical for Tasks 8-9)

**If hooks are broken after state migration:**

```bash
# Step 1: Restore hooks first (most critical)
git log --oneline --grep="hooks"  # Find hook commit
git revert <hook-commit-hash>

# Step 2: Restore state scripts
git revert <task-4-commit> <task-5-commit> <task-3-commit>

# Step 3: Restore from backups if needed
cp .atlas/pipeline-state.json.bak .atlas/pipeline-state.json
cp .atlas/boulder.json.bak .atlas/boulder.json
rm .atlas/state.json  # Remove new file

# Step 4: Verify old system working
./scripts/boulder.py status  # Should use old format
cat .atlas/pipeline-state.json  # Should exist and be valid
```

### Complete Rollback

If migration fails catastrophically:

```bash
# Restore from backups (ALWAYS created by migration --backup)
cp .atlas/pipeline-state.json.bak .atlas/pipeline-state.json
cp .atlas/boulder.json.bak .atlas/boulder.json
rm .atlas/state.json

# Remove migration lock if stuck
rm -f .atlas/migration.lock

# Revert all commits in reverse order
git log --oneline --grep="state|hook"  # Find all related commits
git revert <task-7> <task-9> <task-8> <task-6> <task-5> <task-4> <task-3> <task-2> <task-1> <task-0>

# Verify old system restored
./scripts/boulder.py status  # Should work with old files
pytest tests/ -v  # All tests should pass with old code
```

### Cleanup Commands

```bash
# Remove new state file if corrupted
rm -f .atlas/state.json

# Restore schema
git checkout HEAD -- scripts/lib/state_schema.json

# Remove migration lock
rm -f .atlas/migration.lock

# Verify old state still works
./scripts/boulder.py status  # Should use old format
cat .atlas/pipeline-state.json  # Should be valid
```

---

## Success Criteria

### Verification Commands
```bash
# Verify unified state in use
./scripts/boulder.py status --json | jq '.phase, .momus_iterations, .active_plan'  # Should show all fields

# Verify migration worked
cat .atlas/state.json | jq '.schema_version'  # Should be "unified-v1"

# Verify no split files actively used
rg 'pipeline-state\.json' scripts/ --type py --type sh | grep -v "\.bak\|MIGRATION\|migrate-state"  # Should return 0 active references

# Verify all hooks updated
rg 'pipeline-state\.json' scripts/ -l | grep -v "MIGRATION\|migrate"  # Should return 0

# All tests pass
pytest tests/ -v --cov=scripts  # Coverage >70%

# Integration tests pass
pytest tests/integration/test_hook_state.py -v  # All hook tests pass
```

### Final Checklist
- [ ] All "Must Have" present: Unified .atlas/state.json, migration lock, all 11 hooks updated, Ralph detection, schema version detection
- [ ] All "Must NOT Have" absent: No .atlas/boulders/ references, no boulder_index usage in active code, no uncoordinated updates
- [ ] All tests pass: `pytest tests/ -v`
- [ ] Integration tests pass: `pytest tests/integration/ -v`
- [ ] Migration tested: `./scripts/migrate-state-to-unified.py --dry-run` succeeds
- [ ] Hooks verified: All 11 hooks from audit updated and tested
- [ ] Documentation complete: MIGRATION.md with tested coordinated rollback, CLAUDE.md updated
- [ ] boulder_index.py marked as dead code: Comment added at top
