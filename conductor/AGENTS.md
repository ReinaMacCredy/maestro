<!-- AUTO-GENERATED by /conductor-finish. Do not edit manually. -->

# Conductor Learnings

Knowledge extracted from completed tracks.

## About This File

This file is auto-updated by `/conductor-finish`.
Contains reusable learnings from completed tracks.

**Do not edit manually** - changes may be overwritten.

---

## Commands

- `bd dep add <child> <parent>` - Wire dependencies after bead creation (not auto-mapped from plan)
- `./scripts/validate-links.sh .` - Validate markdown links in codebase
- `./scripts/validate-anchors.sh .` - Validate anchor references
- `sed -i '' 's|old|new|g' file` - macOS in-place sed replacement
- `rg "pattern" --type md -l` - Find files containing pattern
- `tail -n +N file` - Strip first N-1 lines (useful for removing YAML frontmatter)
- `rm -rf skills/X .claude/skills/X` - Delete both hard-linked paths when removing skills
- `bd compact --analyze --json` - Find beads needing summaries
- `bd compact --apply --id <id> --summary "<text>"` - Apply AI summary to bead
- `bd count --status closed --json` - Count closed beads for cleanup threshold
- `bd cleanup --older-than 0 --limit <n> --force` - Remove oldest closed beads
- `bd update <id> --status in_progress` - Claim task
- `bd close <id> --reason completed|skipped|blocked` - Close with explicit reason
- `/conductor-implement` - Execute with TDD checkpoints by default (use `--no-tdd` to disable)
- `wc -l <file>.csv` - Verify CSV row counts match upstream when syncing data files
- `curl -s https://raw.githubusercontent.com/.../file.csv` - Sync CSV data directly from upstream repo
- `uv run skills/conductor/scripts/artifact_index.py` - Build/rebuild SQLite FTS5 index of handoffs
- `uv run skills/conductor/scripts/artifact_index.py --verify` - Check index integrity
- `uv run skills/conductor/scripts/artifact_query.py <query>` - Search archived handoffs with FTS5
- `uv run skills/conductor/scripts/artifact_query.py <query> --json` - JSON output for scripting
- `uv run skills/conductor/scripts/artifact_cleanup.py --dry-run` - Preview handoffs to delete
- `uv run skills/beads/scripts/track_assigner.py <beads.json> --json` - Generate track assignments from beads
- `./scripts/install-global-hooks.sh` - Install Claude Code hooks to ~/.claude/hooks/
- `git branch --show-current` - Get current branch for preflight checks
- `git status --porcelain` - Check for dirty state (empty = clean)
- `git show-ref --verify --quiet "refs/heads/$BRANCH"` - Check if branch exists
- `jq '.workflow.state = "ARCHIVED"' metadata.json > "metadata.json.tmp.$$" && mv "metadata.json.tmp.$$" metadata.json` - Update workflow state atomically
- `/doc-sync` - Sync documentation with code changes
- `/doc-sync --dry-run` - Preview doc changes without applying
- `/doc-sync --force` - Apply all doc changes without prompts
- `sed -n '/^---$/,/^---$/p' "$FILE" | grep '^field:' | cut -d' ' -f2` - Extract YAML frontmatter field value
- `bd close id1 id2 id3 --reason completed` - Close multiple beads at once
- `/conductor-handoff` - Unified handoff command with auto-detect (replaces /create_handoff and /resume_handoff)
- `/conductor-handoff create` - Force CREATE mode with Beads sync and progress tracking
- `/conductor-handoff resume` - Force RESUME mode with Beads context loading
- `ls skills/conductor/references/` - Verify reference structure after migration
- `/conductor-orchestrate` - Spawn parallel workers for track execution
- `bd list --json | jq '. | length'` - Count beads reliably (returns array, not object)
- `grep -l "send_message" skills/orchestrator/agents/**/*.md | wc -l` - Verify all agents have mandatory Agent Mail save
- `mcp__mcp_agent_mail__register_agent` - Register orchestrator identity before spawning workers
- `python skills/orchestrator/scripts/preflight.py detect '<inbox_json>'` - Detect active sessions from Agent Mail inbox
- `python skills/orchestrator/scripts/session_identity.py generate <agent>` - Generate session ID with timestamp
- `python skills/orchestrator/scripts/session_identity.py parse <session_id>` - Parse session ID into components
- `python skills/orchestrator/scripts/session_cleanup.py find-stale '<sessions_json>' --threshold 10` - Find stale sessions
- `ln -s ../skills .claude/skills` - Create symlink for single source of truth (delete contents first)
- `python3 skills/skill-creator/scripts/quick_validate.py skills/<name>` - Validate skill structure and frontmatter
- `wc -l skills/*/SKILL.md` - Check line counts across all skills
- `wc -l *.md docs/*.md` - Line count verification across multiple directories
- `bd list --parent=<epic-id> --status=open --json | jq 'length'` - Check for lingering beads before epic close
- `summarize_thread(thread_id=TRACK_THREAD)` - Read track context before each bead (worker protocol)
- `send_message(to=[self], thread_id=TRACK_THREAD)` - Self-message learnings for next bead (track thread pattern)
- `rg -i "single.?agent|multi.?agent" --type md -l | grep -v CHANGELOG | grep -v archive` - Search for SA/MA references during cleanup
- `rg -i "village|\.beads-village|bv --robot" --type md -l | grep -v archive` - Search for Village references during cleanup
- `macro_start_session()` - Single MCP call for orchestrator/worker initialization (replaces ensure_project + register_agent)
- `bd list --parent <epic-id> --json | jq '[.[] | select(.status == "open")]'` - Filter beads by status
- `bd dep tree <epic-id>` - View dependency tree for epic
- `bd close <id1> --reason completed && bd update <id2> --status in_progress` - Chain close and claim in one command
- `oracle(task="6-dimension design audit", files=[...])` - Amp's built-in oracle tool for design review

## Gotchas

- Skill prerequisite pattern uses markdown `**REQUIRED SUB-SKILL:**` not frontmatter `requires:`
- Design skill's HALT on missing conductor/ was adoption blocker - changed to DEGRADE (standalone mode)
- Lean orchestrator pattern: keep SKILL.md ≤100 lines, move detailed logic to references/
- Hard-linked directories (skills/ ↔ .claude/skills/) - updating one updates both, but explicitly delete both
- Thin skill stubs must include keyword-rich descriptions for AI trigger matching
- Delete operations must wait for reference replacements - deleting too early causes broken references
- Relative paths change when files move - `references/X.md` becomes `./X.md` when you're already in references/
- Archive files contain historical references - don't fix them (they're snapshots)
- Party-mode agent paths need updating when workflow moves
- Phase 3 (Knowledge Merge) is required - if it fails, stop workflow
- Phases 1 & 2 are best-effort - failures should log warnings but continue
- Context Refresh (Phase 4) can be skipped with --skip-refresh flag
- User input A/K must be mapped to JSON values "archive"/"keep"
- Atomic writes use $$ (PID) suffix for temp files to prevent collisions
- CODEMAPS loaded at design session start for codebase context
- docs: and chore: commits don't bump version (changelog only)
- Skill versions in SKILL.md frontmatter are manually updated (not automated)
- HALT vs Degrade: `bd` unavailable = HALT; Agent Mail unavailable = HALT (no fallback since v5.0)
- Session lock staleness: heartbeat protocol (5 min updates); stale = >10 min without heartbeat
- Subagent bd access: read-only (show, ready, list); writes return to main agent
- Idempotency: `bd update` and `bd close` are idempotent; `bd create` is NOT
- planTasks mapping: bidirectional - keep planTasks and beadToTask in sync
- Claude Code hooks must exit 0 even on error (try/catch + graceful exit) to avoid crashing Claude
- Handoffs in conductor/handoffs/<track>/ are git-committed (shareable), archived on /conductor-finish
- Stale handoffs (>7 days) trigger warning on /conductor-handoff resume
- Auto-detect mode uses 7-day threshold: first message + recent handoff = RESUME, else CREATE
- Handoff Beads sync saves context to bd notes for compaction-proof resumability
- FTS5 snippet function: `snippet(handoffs_fts, 2, '>>>', '<<<', '...', 50)` for match highlighting
- artifact-cleanup.py parses dates from filenames (YYYY-MM-DD-HH-MM-trigger.md), not frontmatter
- Concurrent sessions on same codebase may conflict - documented limitation (last writer wins)
- Session continuity is automatic via workflow entry points (ds, /conductor-implement, /conductor-finish)
- Validation state tracked in metadata.json.validation, not LEDGER.md
- State machine uses STRICT vs SOFT enforcement - STRICT transitions HALT, SOFT only WARN
- Default branch names differ by repo: check for BOTH `main` AND `master`
- Auto-archive removes A/K prompt entirely - use `--keep` flag to prevent archiving
- Open beads cause HALT at finish unless `--force` is used
- Branch suffix auto-increments (-v2, -v3) if branch already exists
- `workflow.state` for machine logic, `status` field for human readability
- Doc-sync runs as Phase 7 in `/conductor-finish` (after CODEMAPS)
- Doc-sync errors are non-blocking - workflow continues even if doc-sync fails
- Minor doc changes (path renames, function renames) are auto-applied
- Major doc changes (new features, removed features) prompt user
- Track-switch auto-archives handoffs - switching tracks preserves previous session context
- Handoff operations in Conductor are non-blocking - failures log warnings but never halt commands
- Research: All agents fail → block with `MANUAL_VERIFY`, not silent proceed
- Research: Timeout → return partial results + warning (soft limits), not hard failure
- Research: Network failure → graceful fallback to repo-only mode
- Research: Conflict resolution → auto-prefer highest confidence BUT show conflict summary
- Research: ALWAYS runs - no skip conditions (parallel agents are fast)
- Extraction fidelity: Initial skill extraction may lose philosophical content (e.g., "Why Order Matters"). Fix: copy full SKILL.md first, then split.
- Continuity skill is in marketplace plugin, not local skills/ - can't add direct local dependency checks
- Session start detection without hooks requires implicit trigger (workflow command loading on first message)
- Ad-hoc queries (not triggering `ds`, `/conductor-implement`, etc.) do NOT load handoff history - intentional low-overhead behavior for casual chats
- Agent Mail MCP Failure: HALT - Agent Mail required for orchestrator coordination (no fallback since v5.0)
- Runtime Testing: Integration tests (Agent Mail, worker spawn) require live MCP - skip with `--reason skipped`
- Worker Autonomy: Orchestrator workers CAN self claim/close beads (differs from standard subagent rules)
- Auto-orchestration: fb Phase 6 triggers orchestration automatically after beads are filed
- `metadata.json.beads.orchestrated` flag ensures idempotency - re-running fb skips if already orchestrated
- Duplicate beads during parallel filing: Issues created multiple times require manual closure with reason "Duplicate of X"
- Epic status not auto-updating: Epics remain `open` after all child tasks closed; manually close with `bd close <epic-id> --reason completed`
- jq array parsing: `bd list --json` returns array, not object; use `jq '. | length'` not `jq '.issues | length'`
- Metadata state sync: After `fb` filing, must run `bd sync` before implementation to ensure database state is current
- Agent Mail primary, markdown secondary: Send handoffs to Agent Mail first for FTS5 search, write markdown for git history
- Session ID format: `{BaseAgent}-{timestamp}` (internal), `{BaseAgent} (session HH:MM)` (display)
- rsplit("-", 1) handles hyphenated agent names like Blue-Lake correctly
- Preflight triggers on `/conductor-implement` and `/conductor-orchestrate`, skips for `ds` and query commands
- Agent Mail timeout is 3 seconds - proceed with warning if slow
- Stale threshold is 10 minutes since last heartbeat
- Scripts use stdlib only (no external dependencies) - claudekit-skills pattern
- Test imports need sys.path.insert for the scripts directory when running pytest
- Missing files should use `bd close --reason skipped`, not `--reason blocked`
- Code blocks with `# comments` may be incorrectly parsed as H1 headings by link validators
- Track threads are ephemeral (scoped to single epic) - don't expect cross-epic persistence
- Auto-detect routing requires `metadata.json.beads.planTasks` populated by fb - verify before routing
- Lingering beads can remain after all epic work done - always verify before closing epic
- Epic as blocker shows high dependency count: Even when tasks are Wave 1 ready, `dependency_type: blocks` inflates count - verify tasks not blocked by *other* tasks
- File scope extraction: Tasks with same files → sequential; different files → parallel candidates
- Orchestrator pre-registration is wasteful: Workers should self-register via `macro_start_session` in Step 1
- EPIC START message must go to orchestrator itself (`to=[ORCHESTRATOR_NAME]`) not workers who don't exist yet
- Preflight triage runs even when beads are already filed - check `metadata.beads.status == "complete"` first
- Handoff load runs for fresh sessions - skip when `conductor/handoffs/<track>/` is empty
- Track Assignments parsing redundant when already present - use `parse_track_assignments_table()` directly
- Confirmation prompt re-analyzes file scopes - should use pre-parsed track data
- Skill files live at `.claude/skills/` not `skills/` - verification scripts must use correct paths
- Idempotent Oracle updates: When `## Oracle Audit` section exists, find start marker → find next `##` → replace entire section
- Platform detection for Oracle: Check for oracle tool availability before deciding dispatch method (Amp vs Task)

## Patterns

- **5-Level Skill Hierarchy:** conductor > orchestrator > design > beads > specialized (higher level wins on conflicts)
- **Context-Aware Routing:** Check explicit commands first, then context (conductor/ exists?) for routing
- **6-Phase Finish Workflow:** Pre-flight → Thread Compaction → Beads Compaction → Knowledge Merge → Context Refresh → Archive → CODEMAPS
- **Smart Skip:** Each phase checks if work exists before running
- **Resume Capability:** State files track progress for interrupted workflows
- **A/K Archive Choice:** Archive (move to archive/) / Keep (stay active)
- **State Files First:** Create metadata.json with generation and beads sections in Phase 1.3 BEFORE spec/plan generation
- **Collective State Validation:** Treat 3 state files as atomic unit - HAS_STATE = 0 (none), 1 (partial), 2 (all)
- **Double Diamond Phases:** DISCOVER (diverge) → DEFINE (converge) → DEVELOP (diverge) → DELIVER (converge)
- **A/P/C Checkpoints:** At each phase end: [A] Advanced, [P] Party (multi-agent), [C] Continue
- **Unified Track Creation:** /conductor-newtrack includes spec, plan, beads filing, AND review in one flow
- **Conventional Commits Versioning:** feat: → minor, fix: → patch, feat!: → major
- **COMPLEXITY_EXPLAINER:** Score-based design routing (SPEED <4, ASK 4-6, FULL >6)
- **Execution Routing:** Always FULL mode via orchestrator (even 1 task spawns 1 worker for consistency)
- **RECALL/REMEMBER:** Session lifecycle with anchored format for cross-session context
- **Degradation Signals:** tool_repeat, backtrack, quality_drop, contradiction → 2+ signals triggers compression
- **Anchored Format:** [PRESERVE] markers for Intent and Constraints sections that survive compression
- **Continuity Chain:** `/conductor-implement` (Phase 0.5: load) → work → `/conductor-finish` (Phase 6.5: handoff)
- **State File Consolidation:** Replace N separate state files with sections in a single consolidated file (e.g., metadata.json.beads replaces .fb-progress.json)
- **Track Binding Flow:** null → bound_track → bound_bead → null (lifecycle matches Conductor workflow)
- **Research Protocol:** Parallel agents (Locator + Analyzer + Pattern + Web + Impact) replace sequential grounding
- **Always-On Research:** No skip conditions - research runs at ds, DEVELOP→DELIVER, and newtrack
- **Enforcement Levels:** Advisory (log) → Gatekeeper (block if missing) → Mandatory (block if fails/low confidence)
- **Impact Agent:** Parallel execution with full research at DELIVER phase
- **Layered Auto-Load:** AGENTS.md → Conductor → handoff operations (defense in depth for hookless agents)
- **Workflow-Aware Continuity:** Handoffs tied to entry points (`ds`, `/conductor-implement`, `/conductor-finish`) not generic session events
- **6 Handoff Triggers:** design-end, epic-start, epic-end, pre-finish, manual, idle - each fires at specific integration points
- **Hybrid Handoff Files:** Individual files per handoff (`YYYY-MM-DD_HH-MM-SS-mmm_<track>_<trigger>.md`) + index.md for consolidated log
- **5 Validation Gates:** design (CP1-4 progressive; CP4 full gate) → spec (newtrack) → plan-structure (newtrack) → plan-execution (TDD) → completion (finish)
- **Gate Behavior Matrix:** SPEED mode = all WARN; FULL mode = design/plan-execution/completion HALT + retry (max 2)
- **Validation State in metadata.json:** Track gates_passed, current_gate, retries, last_failure in metadata.json.validation
- **Humanlayer Format:** Gates use Initial Setup → 3-step Validation Process → Guidelines → Checklist → Handoff Integration
- **Wave Execution:** Auto-orchestration uses re-dispatch loop - after wave N workers complete, query `bd ready --json` and spawn wave N+1 for newly-unblocked beads until no more ready beads exist
- **Parallel Wave Execution:** Spawn independent tracks in waves, monitor Agent Mail for completion, re-dispatch when dependencies met
- **5-Category Agent Directory:** research/ review/ planning/ execution/ debug/ under skills/orchestrator/agents/
- **Mandatory send_message():** All sub-agents MUST call send_message() before returning with Status/Files/Decisions/Issues format
- **First-Message Context Load:** fetch_inbox() on session start to load prior context without hooks (Amp-specific)
- **Thin Router Pattern:** Main thread only routes and displays summaries, sub-agents do actual work and report via Agent Mail
- **Session Brain Pattern:** Phase 0 (Preflight) runs before existing orchestrator phases for multi-session coordination
- **Advisory File Reservations:** Warn on file conflicts but don't block - user decides
- **Heartbeat Protocol:** 5-minute intervals, 10-minute stale threshold, auto-cleanup via message age
- **Hybrid Identity:** Internal format for uniqueness, display format for humans
- **Takeover Prompt:** [T]ake over / [W]ait / [I]gnore options for stale sessions
- **Conflict Types:** Track conflicts, file reservation overlaps, bead claim conflicts
- **Hub-and-Spoke Skill Architecture:** maestro-core as central router (~100 lines), all spokes <100 lines each
- **Reference Extraction:** Move detailed content (>100 lines) to references/ subdirectory, keep SKILL.md as concise router
- **Bidirectional Related Links:** Each skill links to related skills; related skills link back for discoverability
- **Track Thread Pattern:** Workers use `track:{AGENT_NAME}:{EPIC_ID}` for bead-to-bead context passing
- **Per-Bead Loop Protocol:** START (register, read thread, reserve, claim) → WORK → COMPLETE (close, save context, release) → NEXT
- **Auto-Detect Parallel Routing:** Check planTasks independence → if ≥2 independent beads → route to orchestrator
- **9-Step Handoff CREATE:** Detect → Parallel Check → Metadata → Secrets → Agent Mail → Beads Sync → Markdown → metadata.json → Activity
- **9-Step Handoff RESUME:** Parse → Agent Mail → File Discovery → Load → Beads Context → Validate → Present → Todos → Activity
- **Hybrid Handoff Storage:** Agent Mail for search (FTS5), markdown for git history
- **Two-Stage File Scope Analysis:** Stage 1 at `/conductor-newtrack` (suggest parallelism), Stage 2 at `/conductor-implement` (confirm with Y/n prompt)
- **Worker 4-Step Protocol:** REGISTER (macro_start_session) → EXECUTE (claim/work/close) → REPORT (send_message) → CLEANUP (release_file_reservations)
- **Lazy References:** Trigger-based reference loading - SKILL.md always loaded, phase-specific references (agent-mail.md, worker-prompt.md) loaded on demand
- **Triage Cache:** Store bead triage results in `metadata.beads.triageCache` with TTL to skip redundant `bv --robot-triage` calls
